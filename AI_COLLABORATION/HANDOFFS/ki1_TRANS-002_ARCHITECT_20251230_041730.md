---
status: COMPLETE
task: TRANS-002
role: ARCHITECT
phase: ARCHITECT
files_changed: []
summary:
  - AI_COLLABORATION/SYSTEM_STATUS.json missing; git status reviewed; ADR_AXIOM_FIRST_FRAMEWORK + AGENT rules read
  - Dekaden-Verteilung scope: global KENO draws across 7 decades via decade = (n-1)//10
  - Plan to add decade distribution analysis module + CLI producing JSON summary/chi2 vs uniform (20% max deviation guardrail)
  - Unit tests planned for mapping, aggregation, chi2, and threshold flags using synthetic draws
  - Working set requested for analysis/data loader/pipeline/test paths and prior decade artifacts
  - CURRENT_STATUS not updated (plan-only, no file changes)
---

# Rule Confirmation
- Rule 1 (SYSTEM_STATUS + ADR/Docs + git status): UNVERIFIED (SYSTEM_STATUS.json missing; git status run; ADR + AGENT read)
- Rule 2 (granularity stated): global
- Rule 3 (semantics defined): decade_bins 0-6 via (n-1)//10, counts per decade, deviation_pct, chi2_p
- Rule 4 (target metric): calibration
- Rule 5 (helper-only boundaries): CONFIRMED
- Rule 6 (reproducibility): UNVERIFIED (plan phase, no command run)

## Task Setup
- Granularity: global
- Semantics: decade_bins=0..6, count/share per decade, deviation_pct vs uniform, chi2_p, pass_flag (<=20% deviation)
- Target metric: calibration

## Repro Commands
- UNVERIFIED (plan only; will be added after implementation)

# Implementierungsplan
1) Anforderungen einsammeln: bestaetige Dekaden-Definition (1-10 -> 0 ... 61-70 -> 6), nutze bestehende Train/Test-Split-Logik (vor 2024 = Train, ab 2024 = Test) und hole Daten via data_loader/runner.
2) Modul bauen: neues `kenobase/analysis/decade_distribution.py` (oder ergaenze bestehendes Feature-Layer) mit Funktionen fuer (a) per-draw decade_vector (len=7), (b) aggregierte counts/shares pro Split, (c) Abweichung vom Uniform-Baseline (expected 1/7) inkl. max deviation %, chi-square p-value, pass_flag bei <=20% Abweichung je Dekade.
3) Pipeline/Config: CLI-Skript `scripts/analyze_decade_distribution.py` oder Hook in bestehendem Analyzer, Parameter fuer input game/source + output path, erzeugt JSON/CSV unter `results/decade_distribution*.json` mit Train/Test-Blocs und Metadaten (timestamp, input file, filters).
4) Tests: Unit-Tests `tests/unit/test_decade_distribution.py` mit synthetischen Draws (gleichverteilte, unausgewogene) fuer Mapping, Aggregation, Deviation/chi2, pass_flag; optional Integration-Test fuer CLI schreibt Datei und Spalten.
5) Doku/Guardrails: kurz README/CLAUDE/plan-Doc Update falls noetig, Logging fuer thresholds, Signal im Runner falls Pass-Flag fehlschlaegt (WARN) aber Prozess nicht stoppt.
6) Deliverables/Outputs: sicherstellen, dass Repro-Kommandos (`python scripts/analyze_decade_distribution.py --game keno --output results/decade_distribution.json`; `pytest tests/unit/test_decade_distribution.py -v`) dokumentiert werden und CURRENT_STATUS nach EXECUTOR-Phase aktualisiert wird.

WORKING_SET_REQUEST:
- kenobase/analysis/number_representations.py
- kenobase/analysis/decade_affinity.py
- kenobase/core/data_loader.py
- kenobase/pipeline/runner.py
- scripts/analyze.py
- tests/unit/test_number_representations.py