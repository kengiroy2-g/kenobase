---
status: COMPLETE
task: TRANS-001
role: ARCHITECT
phase: ARCHITECT
files_changed: []
summary:
  - Context sync done on SYSTEM_STATUS.md plus ADR_AXIOM_FIRST_FRAMEWORK and ADR_PREDICTION_MODEL; SYSTEM_STATUS.json and KI profile ki0_proxy.md missing (Rule 1 caveat).
  - Granularity set to per-KENO-type (pick-count) Summen-Signatur with fields sum_total, type-specific sum_bucket, parity_vector, decade_hist, checksum; target metric accuracy/deterministic reproduction.
  - Data/schema plan: train/test per ADR (pre-2024 train, 2024+ test), signature record with metadata and fixed artifact path (results/summen_signatur*.json), per-type bucket/parity/decade rules plus failure handling.
  - Integration path: new analysis module + CLI + config switches, pipeline hook (analyze/pipeline runner) and CURRENT_STATUS artifact entry to ensure determinism and visibility.
  - Validation path: unit and golden-sample tests on bucket edges/parity/hash determinism, smoke CLI run storing reproducible artifact; repro command to be locked during execution phase.
---
# Rule Confirmation
- Rule 1 (SYSTEM_STATUS + ADR/Docs + git status): UNVERIFIED (SYSTEM_STATUS.json, KI profile ki0_proxy.md missing; git status captured)
- Rule 2 (granularity stated): per-market (per KENO type/pick-count)
- Rule 3 (semantics defined): sum_total, type-specific sum_bucket, parity_vector, decade_hist, checksum/hash
- Rule 4 (target metric): accuracy
- Rule 5 (helper-only boundaries): CONFIRMED
- Rule 6 (reproducibility): UNVERIFIED (no command/artifact run yet)

## Task Setup
- Granularity: per-market (per KENO type/pick-count)
- Semantics: sum_total, type-specific sum_bucket, parity_vector, decade_hist, checksum/hash
- Target metric: accuracy

## Repro Commands
- UNVERIFIED (will define CLI run -> results/summen_signatur*.json during implementation)

# Implementierungsplan
- Step 1: Clarify requirements and missing assets (SYSTEM_STATUS.json, ki0_proxy.md) with stakeholders or confirm absence; lock scope per KENO type/pick-count, expected outputs (train/test) and acceptance (deterministic accuracy vs reference snapshot).
- Step 2: Data and schema design: confirm input sources (Keno CSVs via data_loader), apply ADR train/test split (pre-2024 vs 2024+), define signature record fields (draw_id, date, keno_type/pick_count, sum_total, per-type sum_bucket, parity_vector even/odd counts, decade_hist 1-70 grouped by tens, checksum/hash, metadata timestamp/version/source), choose artifact paths (results/summen_signatur_train.json, results/summen_signatur_test.json) and storage format.
- Step 3: Bucket/parity specification: design per-type bucket ranges (min/max sums, bucket thresholds), parity and decade bin semantics, handling of invalid/missing draws, and deterministic ordering to avoid cross-run drift; document thresholds inline.
- Step 4: Algorithm/API: sketch functions in new module (e.g., kenobase/analysis/summen_signatur.py) for single-draw and batch computation, deterministic hashing, optional caching; CLI entry (scripts/compute_summen_signatur.py) accepting dataset scope/output path/config; config/default.yaml flags for enabling run and output targets.
- Step 5: Integration: plan hook into existing pipelines (scripts/analyze.py or pipeline/runner.py) so signature generation can run with other analyses; ensure artifact registration and CURRENT_STATUS update path; plan to export summary stats for downstream modules (prediction/synthesizer) if needed.
- Step 6: Validation: define unit tests for bucket edges, parity/decade hist correctness, deterministic hash, empty/invalid input handling; golden-sample test comparing against locked fixture artifact; smoke CLI test command (small subset) producing artifact in results/.
- Step 7: Documentation & handoff: outline updates to README/AGENT notes and CURRENT_STATUS describing signature schema, config, and repro command; record final reproducibility command and artifact location in handoff and status once implementation completes.