---
status: COMPLETE
task: TASK-R03
role: ARCHITECT
phase: ARCHITECT
files_changed: []
summary:
  - SYSTEM_STATUS.json nicht auffindbar -> Regel 1 unverified; ADR_PREDICTION_MODEL.md und MODULE_MAP.md gelesen
  - Granularitaet per-market (Bundesland); Semantik: per-number regionale Affinitaet vs global baseline; Zielmetrik: bet-selection
  - Plan skizziert fuer Datenfeld-Pruefung, Loader-Erweiterung, neue Analyse `regional_affinity`, Pipeline/CLI-Ausgabe und optionale Synthese-Integration
  - Akzeptanzkriterien definiert (Artefakte, Tests, Dokumentation, Metrik-Checks)
  - CURRENT_STATUS nicht aktualisiert (Plan-only)
---
# Rule Confirmation
- Rule 1 (SYSTEM_STATUS + ADR/Docs + git status): UNVERIFIED (SYSTEM_STATUS.json fehlt; git status ausgefuehrt; ADR_PREDICTION_MODEL.md & MODULE_MAP.md gelesen)
- Rule 2 (granularity stated): per-market
- Rule 3 (semantics defined): per-number regionale Affinitaet/Bias je Bundesland inkl. Signifikanzscore
- Rule 4 (target metric): bet-selection
- Rule 5 (helper-only boundaries): CONFIRMED (keine Codeaenderungen, nur Plan)
- Rule 6 (reproducibility): UNVERIFIED (Plan-only, keine Runs)

## Task Setup
- Granularity: per-market
- Semantics: Zahlen-Affinitaet pro Bundesland relativ zu globalem Draw-Baseline (Freq, Lift, Signifikanz)
- Target metric: bet-selection

## Repro Commands
- UNVERIFIED (Plan-only; keine Ausfuehrung)

# Implementierungsplan
1) Anforderungen & Datenlage klaeren
   - Quelle fuer Bundesland-Attribut der Ziehungen identifizieren (data/ oder externe Quelle) und Schema dokumentieren (UNVERIFIED bis Datensichtung).
   - Entscheidungsbedarf: regionaler Scope (alle 16 Bundeslaender oder subset), Zeitraumfilter, Umgang mit fehlenden Regionen.
2) Schema/Loader anpassen
   - `kenobase/core/data_loader.py`: Region-Field einlesen/validieren; Normalisierung (z.B. ISO/Bundesland-Name) und Fehlerbehandlung (fallback/Drop).
   - Tests fuer Loader (Mock-CSV mit Region) ergaenzen, bestehende Schnittstellen (pipeline runner, scripts/analyze.py) auf Feld erweitern.
3) Analysemodul „Regional Affinity“ bauen
   - Neues Modul `kenobase/analysis/regional_affinity.py`: Berechnung pro Zahl (1-70) je Bundesland von Frequenz, Lift vs global, Signifikanz (z.B. Chi-Square/Binomial) + Smoothing fuer seltene Regionen.
   - Output-Struktur definieren: `results/regional_affinity.json` mit Metadaten (zeitraum, n_draws, method), pro-region Stats und global baseline.
4) Pipeline/CLI Integration
   - Pipeline Schritt im passenden Runner/Skript (`scripts/analyze.py` oder neuer CLI-Command) zum Triggern der Analyse inkl. Config-Toggles (Zeitraum, min_draws_threshold).
   - Optional: in `kenobase/pipeline/runner.py` aufnehmen, sodass Batch-Runs das Artefakt generieren.
5) Prediction/Synthese Nutzung (optional/enhancement)
   - Falls fuer Empfehlungen relevant: als neue Hypothese (z.B. HYP-013) modellieren, Gewicht/Signifikanz-Logik definieren und in `kenobase/prediction/synthesizer.py` einspeisen; Tier-Logik um regionalen Bias justieren (z.B. Downweight bei Instabilitaet).
   - Dokumentation der Gewichtung und Impact-Analyse gegen ADR-PREDICTION_MODEL aktualisieren.
6) Tests & Validierung
   - Unit-Tests fuer Statistikfunktionen (edge cases: wenige Ziehungen, fehlende Regionen, smoothing).
   - Integrationstest: Synthese/CLI erzeugt `results/regional_affinity.json` mit erwarteter Struktur; Schema-Validation gegen dataclass/pydantic falls vorhanden.
   - Backtest/Explorationsskript optional: Verifiziert, dass regionale Affinitaet nicht reiner Zufall ist (Signifikanz-Threshold), ansonsten Flag UNVERIFIED.
7) Akzeptanzkriterien
   - Artefakt `results/regional_affinity.json` generiert reproduzierbar aus aktuellem Datensatz; enthaelt n_draws und per-region Scores.
   - Loader/Analyse Tests bestehen (neu + bestaendiger Suite).
   - Dokumentation aktualisiert (kurze README/ADR-Notiz mit Methode, Metriken, Grenzen).
   - Wenn in Synthese integriert: Parameter konfigurierbar; Tier/Anti-Avalanche Verhalten unveraendert ausser dokumentiertem Effekt.