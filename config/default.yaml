# Kenobase V2.0 - Default Configuration
# =============================================
# Diese Konfiguration wird vom Config-System (src/core/config.py) geladen.
# Basiert auf ADR-018 Model Laws aus v_master_Criticality.

version: "2.0.0"
debug: false
active_game: keno

# ==========================================
# Pfade für Daten und Output
# ==========================================
paths:
  data_dir: "data"
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  models_dir: "models"
  output_dir: "output"
  logs_dir: "logs"

# ==========================================
# Physics Layer (Model Laws A/B/C)
# Basiert auf ADR-018, ADR-020, ADR-021
# ==========================================
physics:
  enable_model_laws: true

  # Model Law A: Stabilitätsprüfung
  # Ein Pattern gilt als "Gesetz" wenn es >= 90% stabil ist
  stability_threshold: 0.90
  stability_variations: 100

  # Model Law B: Least-Action Principle
  # Wähle die einfachste Pipeline mit gleicher Performance
  enable_least_action: true

  # Model Law C: Criticality Detection (ADR-020)
  # Erkennt "No-Bet" Zonen durch Sensitivitätsanalyse
  criticality_warning: 0.70
  criticality_critical: 0.85

  # Avalanche Theory (ADR-021)
  enable_avalanche: true
  anti_avalanche_mode: true

# ==========================================
# Number Pool Settings (NumberPoolGenerator)
# ==========================================
number_pool:
  # Anzahl Zeitraeume fuer Pool-Generierung
  n_periods: 3
  # Ziehungen pro Zeitraum
  draws_per_period: 10
  # Top-N Zahlen pro Zeitraum (optimiert via TASK-M01)
  top_n_per_period: 11
  # Top-N Zahlen fuer Gesamtanalyse
  top_n_total: 20

# ==========================================
# Analyse-Einstellungen
# ==========================================
analysis:
  # Häufigkeitsanalyse
  min_frequency_threshold: 0.05
  max_frequency_threshold: 0.20

  # Duo/Trio/Quatro Analyse
  # Mindestanzahl Vorkommen für Pattern-Erkennung
  duo_min_occurrences: 3
  trio_min_occurrences: 2
  quatro_min_occurrences: 2

  # Zehnergruppen-Filter
  # Maximum Zahlen pro Zehnergruppe (1-10, 11-20, etc.)
  zehnergruppen_max_per_group: 3

  # 111-Prinzip
  # Sucht nach Kombinationen deren Summe durch 111 teilbar ist
  enable_111_principle: true

  # Rolling Windows für Trendanalyse
  windows: [5, 10, 20, 50]

  # Sum Windows Analysis (TASK-M04)
  # Hypothese: KENO-Summen clustern in bestimmten Fenstern
  sum_windows:
    enabled: true
    bin_width: 20
    # KENO: E[sum] = 20 * (1+70)/2 = 710
    expected_mean: 710
    # Minimale Dichte fuer Cluster-Erkennung (10%)
    min_cluster_density: 0.10
    # Signifikanz-Niveau fuer Chi-Quadrat-Test
    significance_level: 0.05
  # Regionale Affinitaet (Bundesland)
  regional_affinity:
    enabled: true
    # Mindestanzahl Ziehungen pro Region, sonst Skip
    min_draws_per_region: 30
    # Laplace-Smoothing fuer seltene Regionen
    smoothing_alpha: 1.0
    # Z-Score Threshold fuer Signifikanz (zweiseitig)
    z_threshold: 2.0
    # Optional: manuelle Vorgabe der Zahlen pro Ziehung (sonst aus Spiel)
    numbers_per_draw_override: null
  # Summen-Signatur (TRANS-001)
  summen_signatur:
    enabled: true
    keno_types: [2, 4, 6, 8, 9, 10]
    split_date: "2024-01-01"
    output_dir: "results"
    train_output: "results/summen_signatur_train.json"
    test_output: "results/summen_signatur_test.json"
    latest_output: "results/summen_signatur_latest.json"
    bucket_std_low: 0.5
    bucket_std_high: 1.5
    checksum_algorithm: "sha256"

# ==========================================
# Pipeline-Einstellungen
# ==========================================
pipeline:
  # Parallelisierung
  n_workers: 4
  chunk_size: 10000

  # Checkpoint/Resume
  enable_checkpoints: true
  checkpoint_dir: "checkpoints"
  checkpoint_interval: 100000

  # Output
  output_format: "json"
  output_dir: "output"

# ==========================================
# Spieltypen-Konfiguration
# Hot/Cold Thresholds basieren auf erwarteter Frequenz:
#   expected = numbers_to_draw / numbers_range
#   hot = expected * 1.3 (30% über Erwartung)
#   cold = expected * 0.7 (30% unter Erwartung)
# ==========================================
games:
  keno:
    name: "KENO"
    numbers_range: [1, 70]
    numbers_to_draw: 20
    # expected: 20/70 = 28.6%
    hot_threshold: 0.37   # 28.6% * 1.3
    cold_threshold: 0.20  # 28.6% * 0.7

  eurojackpot:
    name: "EuroJackpot"
    numbers_range: [1, 50]
    numbers_to_draw: 5
    bonus_range: [1, 12]
    bonus_count: 2
    # expected: 5/50 = 10%
    hot_threshold: 0.13   # 10% * 1.3
    cold_threshold: 0.07  # 10% * 0.7

  lotto:
    name: "Lotto 6aus49"
    numbers_range: [1, 49]
    numbers_to_draw: 6
    bonus_range: [0, 9]
    bonus_count: 1
    # expected: 6/49 = 12.2%
    hot_threshold: 0.16   # 12.2% * 1.3
    cold_threshold: 0.09  # 12.2% * 0.7

# ==========================================
# Legacy-Kompatibilität (wird migriert)
# ==========================================
legacy:
  # CSV-Dateipfade (relativ zu raw_data_dir)
  keno_file: "keno/KENO_ab_2018.csv"
  eurojackpot_file: "eurojackpot/eurojackpot_archiv_bereinigt.csv"
  lotto_file: "lotto/Lotto_archiv_bereinigt.csv"

  # CSV Parsing
  csv_delimiter: ";"
  csv_date_format: "%d.%m.%Y"
  csv_encoding: "utf-8"

# ==========================================
# Web Scraper Configuration
# ==========================================
scraper:
  # ChromeDriver path (null = auto-detect via webdriver-manager)
  chromedriver_path: null

  # Browser options
  headless: true
  page_load_timeout: 30
  element_wait_timeout: 10

  # Retry settings
  max_retries: 3
  retry_delay: 5

  # Rate limiting (avoid getting blocked)
  request_delay: 2

  # Game-specific URLs
  urls:
    keno: "https://www.lotto-rlp.de/keno/quoten"
    eurojackpot: "https://www.eurojackpot.de/zahlen-quoten/"
    lotto: "https://www.lotto.de/lotto-6aus49/lottozahlen"

# ==========================================
# ML Model Configuration (TASK-P02)
# LightGBM Binary Classifier fuer Zahlenvorhersage
# ==========================================
ml:
  # Model type
  model_type: "lightgbm"

  # LightGBM Hyperparameter
  lightgbm:
    boosting_type: "gbdt"
    objective: "binary"
    num_leaves: 31
    max_depth: -1
    learning_rate: 0.05
    n_estimators: 100
    min_child_samples: 20
    subsample: 0.8
    colsample_bytree: 0.8
    reg_alpha: 0.0
    reg_lambda: 0.0
    class_weight: "balanced"
    random_state: 42

  # Cross-Validation
  cv:
    n_folds: 5
    shuffle: true
    stratified: true

  # Walk-Forward Validation
  walk_forward:
    train_months: 6
    test_months: 1
    step_months: 1
    min_train_samples: 100

  # Hyperparameter Tuning (Optuna)
  tuning:
    enabled: false
    n_trials: 50
    learning_rate_range: [0.01, 0.3]
    num_leaves_range: [15, 63]
    max_depth_range: [3, 12]
    min_child_samples_range: [10, 100]
    subsample_range: [0.6, 1.0]
    colsample_bytree_range: [0.6, 1.0]

  # Acceptance Criteria (TASK-P02)
  acceptance:
    f1_target: 0.50
    stability_target: 0.05  # max std of F1 across CV folds

  # Feature configuration
  features:
    # Use 20 features from FeatureExtractor
    use_registry: true
    # Optional: subset of features
    # include_only: []
    # exclude: []

  # SHAP Explainability (TASK-P14)
  shap:
    enabled: true
    # Check SHAP additivity (sum(shap_values) + base_value == prediction)
    check_additivity: true
    # Maximum features to display in summary plot
    max_display: 10
    # Minimum correlation with native LightGBM importance for validation
    native_correlation_threshold: 0.7

# ==========================================
# Bot Configuration (TASK-P13)
# Telegram/Discord Integration
# ==========================================
bot:
  # Enable/disable platforms
  enable_telegram: false
  enable_discord: false

  # Telegram settings
  telegram:
    # Token via environment variable (never commit tokens!)
    token: "${TELEGRAM_BOT_TOKEN}"
    # Optional: restrict to specific chats (empty = allow all)
    allowed_chat_ids: []

  # Discord settings
  discord:
    # Token via environment variable
    token: "${DISCORD_BOT_TOKEN}"
    # Command prefix
    command_prefix: "!"
    # Optional: restrict to specific guilds (empty = allow all)
    allowed_guild_ids: []

  # Rate limiting (prevent abuse)
  rate_limit:
    requests_per_minute: 10
    cooldown_seconds: 6

  # Prediction cache (reduce computation)
  cache:
    enabled: true
    ttl_seconds: 300

  # Scheduled daily push (optional)
  scheduler:
    enabled: false
    daily_push_time: "08:00"

# ==========================================
# Economic State Configuration (ECON-001)
# Proxies for Axiom A7 (Reset-Zyklen) bet-selection
# ==========================================
economic_state:
  # Rolling window for CV computation
  cv_window: 30
  # Thresholds for state classification
  jackpot_high_threshold: 10000000.0
  cv_high_threshold: 0.5
  # Spieleinsatz deviation thresholds (relative to baseline)
  spieleinsatz_low_ratio: 0.7   # Below this = cooldown indicator
  spieleinsatz_high_ratio: 1.3  # Above this = hot indicator

# ==========================================
# Regime Detection (STATE-001)
# ==========================================
regime_detection:
  enabled: true
  train_split_date: "2024-01-01"
  cv_window: 30
  numbers_range: [1, 70]
  change_point:
    model: "rbf"
    penalty: 5.0
    min_size: 10
    boundary_tolerance: 1
  hmm:
    n_states: 4
    covariance_type: "full"
    n_iter: 200
    random_state: 42
  acceptance:
    accuracy_min: 0.65
    boundary_f1_min: 0.60
    log_likelihood_min: 0.0

# ==========================================
# Logging
# ==========================================
logging:
  level: "INFO"
  file: "logs/kenobase.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
